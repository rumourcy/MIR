{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated tempo:129.20 beats per minute\n",
      "beat_frames: [   5   24   43   63   83  103  122  142  162  182  202  222  242  262  281\n",
      "  301  321  341  361  382  401  421  441  461  480  500  520  540  560  580\n",
      "  600  620  639  658  678  698  718  737  758  777  798  817  837  857  877\n",
      "  896  917  936  957  976  996 1016 1036 1055 1075 1095 1116 1135 1155 1175\n",
      " 1195 1214 1234 1254 1275 1295 1315 1334 1354 1373 1394 1414 1434 1453 1473\n",
      " 1493 1513 1532 1553 1573 1593 1612 1632 1652 1672 1691 1712 1732 1752 1771\n",
      " 1791 1811 1831 1850 1871 1890 1911 1931 1951 1971 1990 2010 2030 2050 2070\n",
      " 2090 2110 2130 2150 2170 2190 2209 2229 2249 2269 2289 2309 2328 2348 2368\n",
      " 2388 2408 2428 2448 2468 2488 2508 2527 2547]\n",
      "Saving ouput to beat_times.csv\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import librosa\n",
    "\n",
    "filename = librosa.util.example_audio_file()\n",
    "\n",
    "y, sr = librosa.load(filename)\n",
    "\n",
    "tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "\n",
    "print('Estimated tempo:{:.2f} beats per minute'.format(tempo))\n",
    "\n",
    "beat_times = librosa.frames_to_time(beat_frames, sr=sr)\n",
    "\n",
    "print('beat_frames:', beat_frames)\n",
    "\n",
    "print('Saving ouput to beat_times.csv')\n",
    "librosa.output.times_csv('beat_times.csv', beat_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: (1355168,)\n",
      "beat_frames: (98,)\n",
      "mfcc: (13, 2647)\n",
      "mfcc_delta: (13, 2647)\n",
      "beat_mfcc_delta: (26, 99)\n",
      "chromagram: (12, 2647)\n",
      "chroma: (12, 99)\n",
      "beat_features: (38, 99)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "y, sr = librosa.load(librosa.util.example_audio_file())\n",
    "\n",
    "print('y:', y.shape)\n",
    "\n",
    "hop_length = 512\n",
    "\n",
    "y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "\n",
    "tempo, beat_frames = librosa.beat.beat_track(y=y_percussive, sr=sr)\n",
    "print('beat_frames:', beat_frames.shape)\n",
    "\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13)\n",
    "print('mfcc:', mfcc.shape)\n",
    "\n",
    "mfcc_delta = librosa.feature.delta(mfcc)\n",
    "print('mfcc_delta:', mfcc_delta.shape)\n",
    "\n",
    "beat_mfcc_delta = librosa.util.sync(np.vstack([mfcc, mfcc_delta]), beat_frames)\n",
    "print('beat_mfcc_delta:', beat_mfcc_delta.shape)\n",
    "\n",
    "chromagram = librosa.feature.chroma_cqt(y=y_harmonic, sr=sr)\n",
    "print('chromagram:', chromagram.shape)\n",
    "\n",
    "beat_chroma = librosa.util.sync(chromagram, beat_frames, aggregate=np.median)\n",
    "print('chroma:', beat_chroma.shape)\n",
    "\n",
    "beat_features = np.vstack([beat_chroma, beat_mfcc_delta])\n",
    "print('beat_features:', beat_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
